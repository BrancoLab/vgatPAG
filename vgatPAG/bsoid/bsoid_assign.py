

"""
    See explanation here: https://github.com/YttriLab/B-SOID/blob/master/docs/bsoid_gmm.md

    and here: https://github.com/YttriLab/B-SOID/blob/master/bsoid/bsoid_gmm.m

    -------------------------------------------------------------------------------------------------------------------------------------------------
    BSOID_GMM     Behavioral Segmentation of Open-Field Behavior based on Gaussian Mixture Models (GMM) in DeepLabCut. This unsupervised learning algorithm
              parses out action groups based on statistically different feature distribution.
   

   INPUTS:
   DATA    6-body parts (x,y) matrix outlining the tetrapod animal over time videotaped from the bottom looking up. Rows represents time.
           Columns 1 & 2 tracks snout; columns 3 to 6 tracks the two front paws; columns 7 to 10 tracks the two hind paws;
           columns 11 & 12 tracks the base of the tail. Tested on tracking data generated by DeepLabCut 2.0.
   FPS    Rounded frame rate, can use VideoReader/ffmpeg(linux command) to automatically detect the input video fps.
   COMP    If you desire 1 classifier built on multiple animals, set this parameter to 1; Otherwise, this will build individual classifier/.csv file.
           Default is 1. 
   SMTH_HSTRY    BOXCAR smoothing using number of frames from before. Default ~40ms before.
   SMTH_FUTR    BOXCAR smoothing using number of frames from after. Default ~40ms after.
   KCLASS    Maximum number of classes that the Gaussian Mixture Model will try to parse out. Default 30.
   IT    Number of iterations to potentially find global, instead of local optimum. Default 20.

   OUTPUTS:
   F_10FPS    Compiled features that were used to cluster, 10fps temporal resolution.
   TSNE_FEATS    A 3-dimensional space where 7 features are embedded using t-Distributed Stochastic Neighbor Embedding. The perplexity (p) here can be
                 modified to the user liking if needed.                 
   GRP    Statistically different groups of actions based on data. Output is 10Hz matching F_10FPS and TSNE_FEATS.
   LLH    Log-likelihood to see if the EM algorithm converged.
   BSOID_FIG    Graph showing the how Gaussian Mixture Models grouped data points in the 3D action space.

   Created by Alexander Hsu, Date: 070819
   Contact ahsu2@andrew.cmu.edu
"""


def bsoid_assign(data, fps, comp, kclass, it):
    win_len = np.int(np.round(0.05/(1/fps))*2-1)

    print('Obtaining features from dataset... \n')
    start_time = time.time()
    feats = list()
    for m in range(len(data)):

        ## Obtain features, 4 distance features and 3 time-varying speed/angle features
        dataRange = len(data[m])

        fpd = data[m][:,2:4] - data[m][:,4:6]
        cfp = np.vstack(((data[m][:,2]+data[m][:,4])/2,(data[m][:,3]+data[m][:,5])/2)).T
        cfpLen = len(cfp)
        cfp_pt = np.vstack(([cfp[:,0]-data[m][:,10],cfp[:,1]-data[m][:,11]])).T
        chp = np.vstack((((data[m][:,6]+data[m][:,8])/2),((data[m][:,7]+data[m][:,9])/2))).T
        chp_pt = np.vstack(([chp[:,0] - data[m][:,10],chp[:,1] - data[m][:,11]])).T
        sn_pt = np.vstack(([data[m][:,0] - data[m][:,10],data[m][:,1] - data[m][:,11]])).T
        fpd_norm = np.zeros(dataRange)
        cfp_pt_norm = np.zeros(dataRange)
        chp_pt_norm = np.zeros(dataRange)
        sn_pt_norm = np.zeros(dataRange)
        fpd_norm_smth = np.zeros(dataRange)
        sn_cfp_norm_smth = np.zeros(dataRange)
        sn_chp_norm_smth = np.zeros(dataRange)
        sn_pt_norm_smth = np.zeros(dataRange)
        for i in range(1,dataRange):
            fpd_norm[i] = np.array(np.linalg.norm(data[m][i,2:4] - data[m][i,4:6]))
            cfp_pt_norm[i] = np.linalg.norm(cfp_pt[i,:])
            chp_pt_norm[i] = np.linalg.norm(chp_pt[i,:])
            sn_pt_norm[i] = np.linalg.norm(sn_pt[i,:])
        fpd_norm_smth = boxcar_center(fpd_norm,win_len)
        sn_cfp_norm_smth = boxcar_center(sn_pt_norm- cfp_pt_norm,win_len)
        sn_chp_norm_smth = boxcar_center(sn_pt_norm - chp_pt_norm,win_len)
        sn_pt_norm_smth = boxcar_center(sn_pt_norm,win_len)
        sn_pt_ang = np.zeros(dataRange-1)
        sn_disp = np.zeros(dataRange-1)
        pt_disp = np.zeros(dataRange-1)
        sn_pt_ang_smth = np.zeros(dataRange-1)
        sn_disp_smth = np.zeros(dataRange-1)
        pt_disp_smth = np.zeros(dataRange-1)
        for k in range(0,dataRange - 1):
            b_3d = np.hstack([sn_pt[k + 1,:],0])
            a_3d = np.hstack([sn_pt[k,:],0])
            c = np.cross(b_3d,a_3d)
            sn_pt_ang[k] = np.dot(np.dot(np.sign(c[2]),180)/np.pi , math.atan2(np.linalg.norm(c),np.dot(sn_pt[k,:],sn_pt[k + 1,:])))
            sn_disp[k] = np.linalg.norm(data[m][k + 1,0:2] - data[m][k,0:2])
            pt_disp[k] = np.linalg.norm(data[m][k + 1,10:12] - data[m][k,10:12])
        sn_pt_ang_smth=boxcar_center(sn_pt_ang,win_len)
        sn_disp_smth=boxcar_center(sn_disp,win_len)
        pt_disp_smth=boxcar_center(pt_disp,win_len)
        feats.append(np.vstack((sn_cfp_norm_smth[1:],sn_chp_norm_smth[1:],fpd_norm_smth[1:],
                                        sn_pt_norm_smth[1:],sn_pt_ang_smth[:],sn_disp_smth[:],pt_disp_smth[:])))
    print("--- Feature extraction took s seconds ---"  (time.time() - start_time))  


    #Feature compilation
    start_time = time.time()
    if comp == 0:
      f_10fps = list()
      tsne_feats = list()
      labels = list()   
    for n in range(0,len(feats)):
      feats1 = np.zeros(len(data[n]))
      for k in range(round(fps / 10)-1,len(feats[n][0]),round(fps / 10)):
        if k > round(fps/10)-1:
          feats1 = np.concatenate((feats1.reshape(feats1.shape[0],feats1.shape[1]),
                                  np.hstack((np.mean((feats[n][0:4,range(k - round(fps / 10),k)]), axis = 1),
                                              np.sum((feats[n][4:7,range(k - round(fps / 10),k)]), axis = 1))).reshape(len(feats[0]),1)),axis = 1)
        else:
          feats1 = np.hstack((np.mean((feats[n][0:4,range(k - round(fps / 10),k)]), axis = 1),
                              np.sum((feats[n][4:7,range(k - round(fps / 10),k)]), axis = 1))).reshape(len(feats[0]),1)
      print("--- Feature compilation took s seconds ---"  (time.time() - start_time))


      if comp == 1:
        if n > 0:
          f_10fps = np.concatenate((f_10fps,feats1),axis = 1)
        else:
          f_10fps = feats1
      else:
        f_10fps.append(feats1)
        if len(f_10fps[n]) < 15000:
          p = 50
          exag = 12
          lr = 200
        else:
          p = round(f_10fps[n].shape[1]/300)
          exag = round(f_10fps[n].shape[1]/1200)
          lr = round(np.log(f_10fps[n].shape[1])/0.04)
        
        
        start_time = time.time()
        ## Run t-SNE dimensionality reduction
        np.random.seed(0) # For reproducibility
        print('Running the compiled data through t-SNE collapsing the 7 features onto 3 action space coordinates... \n')
        tsne_feats_i =TSNE(n_components=3,perplexity=p, early_exaggeration=exag, learning_rate=lr, n_jobs=8).fit_transform(f_10fps[n].T)
        tsne_feats.append(tsne_feats_i)
        print("--- TSNE embedding took s seconds ---"  (time.time() - start_time))

        ## Run a Gaussian Mixture Model Expectation Maximization to group the t-SNE clusters
        start_time = time.time()
        gmm = mixture.GaussianMixture(n_components=kclass, covariance_type='full', tol=0.001, reg_covar=1e-06, max_iter=100, n_init=it, init_params='random').fit(tsne_feats_i)
        grp = gmm.predict(tsne_feats_i)
        labels.append(grp)
        print("--- Gaussian mixtures took s seconds ---"  (time.time() - start_time))
        print(" Plotting t-SNE with GMM assignments... ")
        uk = list(np.unique(labels))
        uniqueLabels = []
        for i in labels:
          indexVal = uk.index(i)
          uniqueLabels.append(indexVal)
        R = np.linspace(0,1,len(uk))
        color=plt.cm.hsv(R)
        fig = go.Figure(data=[go.Scatter3d(x=tsne_feats_i[:,0], y=tsne_feats_i[:,1], z=tsne_feats_i[:,2], mode='markers', 
                                     marker=dict(size=2.5, color=color[uniqueLabels], opacity=0.8))])
        fig.show()
        print('TADA! \n')
        
    if comp == 1:
        if len(f_10fps) < 15000:
          p = 50
          exag = 12
          lr = 200
        else:
          p = round(f_10fps.shape[1]/300)
          exag = round(f_10fps.shape[1]/1200)
          lr = round(np.log(f_10fps.shape[1])/0.04)
        start_time = time.time()
        ## Run t-SNE dimensionality reduction
        np.random.seed(0) # For reproducibility
        print('Running the compiled data through t-SNE collapsing the 7 features onto 3 action space coordinates... \n')
        tsne_feats=TSNE(n_components=3,perplexity=p, early_exaggeration=exag, learning_rate=lr, n_jobs=8).fit_transform(f_10fps.T)
        print("--- TSNE embedding took s seconds ---"  (time.time() - start_time))
        ## Run a Gaussian Mixture Model Expectation Maximization to group the t-SNE clusters
        start_time = time.time()
        gmm = mixture.GaussianMixture(n_components=kclass, covariance_type='full', tol=0.001, reg_covar=1e-06, max_iter=100, n_init=it, init_params='random').fit(tsne_feats)
        labels = gmm.predict(tsne_feats)
        print("--- Gaussian mixtures took s seconds ---"  (time.time() - start_time))
        print(" Plotting t-SNE with GMM assignments... ")
        uk = list(np.unique(labels))
        uniqueLabels = []
        for i in labels:
          indexVal = uk.index(i)
          uniqueLabels.append(indexVal)
        R = np.linspace(0,1,len(uk))
        color=plt.cm.hsv(R)
        fig = go.Figure(data=[go.Scatter3d(x=tsne_feats[:,0], y=tsne_feats[:,1], z=tsne_feats[:,2], mode='markers', 
                                     marker=dict(size=2.5, color=color[uniqueLabels], opacity=0.8))])
        fig.show()
        print('TADA! \n')

    return f_10fps,tsne_feats,np.array(uniqueLabels),fig

