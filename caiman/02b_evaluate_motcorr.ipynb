{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python361064bitcaiconda8c51914467a4460685b7f212a4ce3dd5",
   "display_name": "Python 3.6.10 64-bit ('cai': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate motion correction\n",
    "Compute metrics to evaluate the quality of the motion correction "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    get_ipython().magic(u'load_ext autoreload')\n",
    "    get_ipython().magic(u'autoreload 2')\n",
    "    get_ipython().magic(u'matplotlib qt')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "from shutil import copyfile\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.utils.visualization import inspect_correlation_pnr\n",
    "from caiman.motion_correction import compute_metrics_motion_correction\n",
    "\n",
    "import logging\n",
    "from fancylog import fancylog\n",
    "import fancylog as package\n",
    "\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from fcutils.file_io.io import load_yaml\n",
    "from fcutils.file_io.utils import check_create_folder, get_file_name, check_file_exists\n",
    "from fcutils.plotting.utils import clean_axes, save_figure, add_colorbar_to_img\n",
    "from fcutils.plotting.colors import *\n",
    "\n",
    "from movie_visualizer import compare_videos\n",
    "from utils import load_mmap_video_caiman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get files and metadata\n",
    "\n",
    "The evaluation of MC is based on 3 videos:\n",
    "\n",
    "- raw (ffcsub) vide\n",
    "- raw with rigid MC \n",
    "- raw with piece wise MC\n",
    "\n",
    "Note that the shifts for the motion correction are computed on transformed and normalized video, but they're then used to correct the raw video. \n",
    "This allows us to estimate the quality of the motion correction without worrying about how the normalization altered the values in the videos (which would throw off some of the metrics used here)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "2020-04-18 18:12:39 PM - INFO - MainProcess fancylog.py:271 - Starting logging\n2020-04-18 18:12:39 PM - INFO - MainProcess fancylog.py:273 - Multiprocessing-logging module not found, not logging multiple processes.\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:8 - ANALYSIS METADATA FILE:\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:10 - experimenter:  Federico\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:10 - fld:  D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:10 - outputfld:  MC_output_crop_downscale\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:10 - raw_video:  19JUN05_BF164p1_v1_ds126_crop_raw.tif\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:10 - ffcsub_video:  19JUN05_BF164p1_v1_ds126_crop_ffcSub.tiff\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:10 - ffcsub_params:  {'downscaling': 0.2, 'sigma': 25, 'mean': 'movie_mean', 'norm_by': 'subtraction'}\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:10 - fft_bandpass_params:  [{'large_structures': 80}, {'small_structures': 5}, {'suppress_stripes': 'None'}, {'autoscale': True}, {'saturate': False}, {'display': False}]\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:10 - fftfilt_video:  19JUN05_BF164p1_v1_ds126_crop_ffcSub_fftfilt.tif\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:10 - norm_by_fft_video:  19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft.tif\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:10 - video_for_mc:  norm_by_fft_video\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:10 - transformed_mc_video:  19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft_els__d1_109_d2_92_d3_1_order_C_frames_22662_.mmap\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:10 - raw_mc_video:  19JUN05_BF164p1_v1_ds126_crop_ffcSub_els_d1_109_d2_92_d3_1_order_C_frames_22662_.mmap\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:10 - video_for_cnmfe_fit:  raw_mc_video\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:10 - components_qc_params:  {'filter_by_size': True, 'remove_duplicate_components': True}\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:11 - Output folder: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\MC_output_crop_downscale\n2020-04-18 18:12:39 PM - INFO - MainProcess <ipython-input-2-d56b5bb3f5b5>:17 - Video paths: {'raw': 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\\\\19JUN05_BF164p1_v1_ds126_crop_ffcSub.tiff', 'raw_pw_mc': 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\\\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_els_d1_109_d2_92_d3_1_order_C_frames_22662_.mmap', 'raw_rig_mc': 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\\\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_rig_d1_109_d2_92_d3_1_order_C_frames_22662_.mmap', 'transf_pw_mc': 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\\\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft_els__d1_109_d2_92_d3_1_order_C_frames_22662_.mmap', 'transf_rig_mc': 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\\\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft_rig__d1_109_d2_92_d3_1_order_C_frames_22662_.mmap'}\n"
    }
   ],
   "source": [
    "fld = 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05' # <- which folder/recording we are working on\n",
    "metadata = load_yaml(os.path.join(fld, \"01_PARAMS\", \"analysis_metadata.yml\"))\n",
    "output_fld = os.path.join(fld, metadata['outputfld']) # plots and other stuff will be saved here\n",
    "\n",
    "# Setup logging\n",
    "logging_file = fancylog.start_logging(os.path.join(fld, \"02_LOGS\"), package, file_log_level=\"INFO\", verbose=False, filename='motion_correction_evaluation_logs')\n",
    "\n",
    "logging.info(\"ANALYSIS METADATA FILE:\")\n",
    "for k,v in metadata.items():\n",
    "    logging.info(f\"{k}:  {v}\")\n",
    "logging.info(f\"Output folder: {output_fld}\")\n",
    "\n",
    "# Get paths to videos\n",
    "paths_file = os.path.join(output_fld, \"video_paths.yml\")\n",
    "check_file_exists(paths_file, raise_error=True)\n",
    "video_paths = load_yaml(paths_file)\n",
    "logging.info(f\"Video paths: {video_paths}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect videos\n",
    "Use this code to look at the videos side by side. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "napari requires a Qt event loop to run. To create one, try one of the following: \n  - use the `napari.gui_qt()` context manager. See https://github.com/napari/napari/tree/master/examples for usage examples.\n  - In IPython or a local Jupyter instance, use the `%gui qt` magic command.\n  - Launch IPython with the option `--gui=qt`.\n  - (recommended) in your IPython configuration file, add or uncomment the line `c.TerminalIPythonApp.gui = 'qt'`. Then, restart IPython.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2419a2c9c379>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcompare_videos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'raw'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrigid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvideo_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'raw_rig_mc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvideo_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'raw_pw_mc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Federico\\Documents\\GitHub\\vgatPAG\\caiman\\movie_visualizer.py\u001b[0m in \u001b[0;36mcompare_videos\u001b[1;34m(rgb, contrast_limits, fps, notebook, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnapari\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndisplay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mttl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cai\\lib\\site-packages\\napari\\viewer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, title, ndisplay, order, axis_labels, show)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[1;34m\" Then, restart IPython.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             )\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mlogopath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'resources'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'logo.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: napari requires a Qt event loop to run. To create one, try one of the following: \n  - use the `napari.gui_qt()` context manager. See https://github.com/napari/napari/tree/master/examples for usage examples.\n  - In IPython or a local Jupyter instance, use the `%gui qt` magic command.\n  - Launch IPython with the option `--gui=qt`.\n  - (recommended) in your IPython configuration file, add or uncomment the line `c.TerminalIPythonApp.gui = 'qt'`. Then, restart IPython."
     ]
    }
   ],
   "source": [
    "compare_videos(raw = video_paths['raw'], rigid=video_paths['raw_rig_mc'], pw=video_paths['raw_pw_mc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute quality metrics\n",
    "\n",
    "### Correlation\n",
    "Look at the correlation between each frame and a reference frame (e.g. avg frame across entire video). If the motion correction worked, the correlation of the motion corrected frames should be higher than that of the raw frame (if stuff moves frames wont't be correlated). This metric is in part influenced by neural activity but not too much. \n",
    "\n",
    "### Crispness\n",
    "Another metric is cripsness. If the motion correction worked. The average frame should be crisper (less blurry). \n",
    "\n",
    "### Optic flow\n",
    "Finally the last metric checks the optic flow across the video. If the video has been correctly motion corrected, the residual optic flow should be minimal. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "2020-04-18 18:12:41 PM - INFO - MainProcess <ipython-input-4-a5f776b63455>:7 - Computing quality metrics\n2020-04-18 18:12:43 PM - INFO - MainProcess motion_correction.py:2526 - [0, None, 0, None]\n2020-04-18 18:13:01 PM - INFO - MainProcess motion_correction.py:2558 - Compute optical flow .. \n2020-04-18 18:13:42 PM - INFO - MainProcess motion_correction.py:2526 - [0, None, 0, None]\n2020-04-18 18:14:08 PM - INFO - MainProcess motion_correction.py:2558 - Compute optical flow .. \n2020-04-18 18:14:56 PM - INFO - MainProcess motion_correction.py:2526 - [0, None, 0, None]\n2020-04-18 18:15:22 PM - INFO - MainProcess motion_correction.py:2558 - Compute optical flow .. \n"
    }
   ],
   "source": [
    "# compute metrics for the results (takes ~5 mins)\n",
    "Yr, dims, T, images = load_mmap_video_caiman(video_paths['raw_rig_mc'])\n",
    "winsize = 100\n",
    "swap_dim = False\n",
    "resize_fact_flow = .2    # downsample for computing ROF\n",
    "\n",
    "logging.info(\"Computing quality metrics\")\n",
    "\n",
    "args = [dims[0], dims[1], swap_dim]\n",
    "kwargs = dict(winsize=winsize, play_flow=False, resize_fact_flow=resize_fact_flow)\n",
    "\n",
    "# Compute for raw video\n",
    "tmpl_orig, correlations_orig, flows_orig, norms_orig, crispness_orig = compute_metrics_motion_correction(video_paths['raw'], *args, **kwargs)\n",
    "\n",
    "# Compute for rigid MC\n",
    "tmpl_rig, correlations_rig, flows_rig, norms_rig, crispness_rig = compute_metrics_motion_correction(video_paths['raw_rig_mc'], *args, **kwargs)\n",
    "\n",
    "# Compute for piecewise MC\n",
    "tmpl_els, correlations_els, flows_els, norms_els, crispness_els = compute_metrics_motion_correction(video_paths['raw_pw_mc'], *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy metric files to the output directory\n",
    "ttles = [\"raw\", \"rigid\", \"piecewise\"]\n",
    "files = [video_paths['raw'], video_paths['raw_rig_mc'], video_paths['raw_pw_mc']]\n",
    "metric_files = [os.path.join(fld, get_file_name(f)+\"._metrics.npz\") for f in files]\n",
    "\n",
    "_metric_files = []\n",
    "for f in metric_files:\n",
    "    if not os.path.isfile(f):\n",
    "        f = f.replace(\"._metrics.npz\", \"_metrics.npz\")\n",
    "    _metric_files.append(f)\n",
    "\n",
    "dests = [os.path.join(os.path.split(f)[0], output_fld, os.path.split(f)[1]) for f in _metric_files]\n",
    "\n",
    "for src, dest in zip(_metric_files, dests):\n",
    "    copyfile(src, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot quality metrics\n",
    "\n",
    "### Correlation"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "WARNING: Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n2020-04-18 18:16:14 PM - WARNING - MainProcess _qt.py:187 - Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n saved figure at: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\MC_output_crop_downscale\\frames_correlation_to_reference\n"
    }
   ],
   "source": [
    "# Plot correlation with mean frame\n",
    "f = plt.figure(figsize = (20,10))\n",
    "\n",
    "# Plot correlation to mean frame for all frames\n",
    "ax = plt.subplot(211)\n",
    "ax.plot(correlations_orig, color=goldenrod, label=\"original\", lw=3, alpha=1)\n",
    "ax.plot(correlations_rig, color=darkseagreen, label=\"rigid\", lw=2, alpha=.8)\n",
    "ax.plot(correlations_els, color=salmon, label=\"piecewise\", lw=2, alpha=.6)\n",
    "ax.set(title=\"Frame by frame correlation to mean frame\", xlabel=\"frame\", ylabel=\"correlation\")\n",
    "ax.legend()\n",
    "\n",
    "# Plot original vs rigid correlation\n",
    "ax = plt.subplot(234)\n",
    "ax.scatter(correlations_orig, correlations_rig, color=darkseagreen, alpha=.3)\n",
    "ax.plot([0, 1], [0, 1], '--', lw=2, alpha=.8, color=[.4, .4, .4])\n",
    "ax.set(xlabel=\"original\", ylabel=\"rigid\",\n",
    "            xlim=[.3, .7], ylim=[.3, .7])\n",
    "ax.axis('square')\n",
    "\n",
    "# Plot original vs piecewise\n",
    "ax = plt.subplot(235)\n",
    "ax.scatter(correlations_orig, correlations_els, color=salmon, alpha=.3)\n",
    "ax.plot([0, 1], [0, 1], '--', lw=2, alpha=.8, color=[.4, .4, .4])\n",
    "ax.set(xlabel=\"original\", ylabel=\"piecewise\",\n",
    "            xlim=[.3, .7], ylim=[.3, .7])\n",
    "_ = ax.axis('square')\n",
    "\n",
    "\n",
    "# Plot rigid vs piecewise\n",
    "ax = plt.subplot(236)\n",
    "ax.scatter(correlations_rig, correlations_els, color=blackboard, alpha=.3)\n",
    "ax.plot([0, 1], [0, 1], '--', lw=2, alpha=.8, color=[.4, .4, .4])\n",
    "ax.set(xlabel=\"rigid\", ylabel=\"piecewise\",\n",
    "            xlim=[.3, .7], ylim=[.3, .7])\n",
    "_ = ax.axis('square')\n",
    "\n",
    "# save\n",
    "clean_axes(f)\n",
    "save_figure(f, os.path.join(output_fld, \"frames_correlation_to_reference\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crispness"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "2020-04-18 18:16:17 PM - INFO - MainProcess <ipython-input-7-edbb2de397c1>:3 - Crispness:\n  original: 169\n  rigid:  161\n  piecewise: 165\n"
    }
   ],
   "source": [
    "# print crispness values\n",
    "msg = f\"Crispness:\\n  original: {int(crispness_orig)}\\n  rigid:  {int(crispness_rig)}\\n  piecewise: {int(crispness_els)}\"\n",
    "logging.info(msg)\n",
    "\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optic flow"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "WARNING: Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n2020-04-18 18:16:17 PM - WARNING - MainProcess _qt.py:187 - Attribute Qt::AA_EnableHighDpiScaling must be set before QCoreApplication is created.\n saved figure at: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\MC_output_crop_downscale\\optic_flow_summary\n"
    }
   ],
   "source": [
    "# plot the results of Residual Optical Flow\n",
    "f, axarr = plt.subplots(figsize = (20,10), ncols=2, nrows=3)\n",
    "\n",
    "for i, (fl, ttl) in enumerate(zip(dests, ttles)):\n",
    "    if not os.path.isfile(fl):\n",
    "        raise ValueError\n",
    "    else:\n",
    "        ld = np.load(fl)\n",
    "        \n",
    "    if fl.endswith(\"mmap\"):\n",
    "        mean_img = np.mean(cm.load(fl[:-12] + 'mmap'), 0)[12:-12, 12:-12]\n",
    "    else:\n",
    "        mean_img = np.mean(cm.load(video_paths['raw']), 0)[12:-12, 12:-12]\n",
    "\n",
    "\n",
    "    lq, hq = np.nanpercentile(mean_img, [.5, 99.5])\n",
    "\n",
    "    axarr[i, 0].imshow(mean_img, vmin=lq, vmax=hq)\n",
    "    axarr[i, 0].set(title=\"Mean image \" + ttl)\n",
    "\n",
    "    flows = ld['flows']\n",
    "    img = axarr[i, 1].imshow(np.mean(np.sqrt(flows[:, :, :, 0]**2 + flows[:, :, :, 1]**2), 0))\n",
    "    add_colorbar_to_img(img, axarr[i, 1], f)\n",
    "\n",
    "    axarr[i, 1].set(title=\"mean optical flow \" + ttl)\n",
    "\n",
    "# save\n",
    "f.tight_layout()\n",
    "clean_axes(f)\n",
    "save_figure(f, os.path.join(output_fld, \"optic_flow_summary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save residual optic flow for each condition\n",
    "This is used to later on plot the components found by CNMF-E over the residual optic flow to exclud components in poorly motion corrected parts of the frame"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "2020-04-18 18:16:28 PM - INFO - MainProcess <ipython-input-9-4f805e730eeb>:13 - Saving residual optic flow for raw at: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\MC_output_crop_downscale\\residual_opticflow_raw\n2020-04-18 18:16:30 PM - INFO - MainProcess <ipython-input-9-4f805e730eeb>:13 - Saving residual optic flow for rigid at: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\MC_output_crop_downscale\\residual_opticflow_rigid\n2020-04-18 18:16:32 PM - INFO - MainProcess <ipython-input-9-4f805e730eeb>:13 - Saving residual optic flow for piecewise at: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\MC_output_crop_downscale\\residual_opticflow_piecewise\n"
    }
   ],
   "source": [
    "# Save the average residual flow for each condition as an image\n",
    "cmap = \"viridis\"\n",
    "\n",
    "for fl, ttl in zip(dests, ttles):\n",
    "    ld = np.load(fl)\n",
    "    mean_flow = np.mean(np.sqrt(ld['flows'][:, :, :, 0]**2 + ld['flows'][:, :, :, 1]**2), 0)\n",
    "\n",
    "    save_path = os.path.join(output_fld, f\"residual_opticflow_{ttl}\")\n",
    "\n",
    "    plt.imsave(save_path, mean_flow, cmap=cmap)\n",
    "    np.save(save_path+\".npy\", mean_flow)\n",
    "\n",
    "    logging.info(f\"Saving residual optic flow for {ttl} at: {save_path}\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}