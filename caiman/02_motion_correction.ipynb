{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python361064bitcaiconda8c51914467a4460685b7f212a4ce3dd5",
   "display_name": "Python 3.6.10 64-bit ('cai': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Correction using the NoRMCorre algorithm\n",
    "\n",
    "Can use both rigid and piecewise motion correction. The original motion correction algorithm is described in this paper:\n",
    "https://www.sciencedirect.com/science/article/pii/S0165027017302753?via%3Dihub\n",
    "\n",
    "More details and tips here: https://caiman.readthedocs.io/en/master/CaImAn_Tips.html#motion-correction-tips\n",
    "\n",
    "And an example pipeline here:  https://github.com/flatironinstitute/CaImAn/blob/6c5c3b6117b71b6e8b44f62fc26fd3b3d914de12/demos/notebooks/demo_motion_correction.ipynb"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    get_ipython().magic(u'load_ext autoreload')\n",
    "    get_ipython().magic(u'autoreload 2')\n",
    "    get_ipython().magic(u'matplotlib qt')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "\n",
    "\n",
    "import logging\n",
    "from fancylog import fancylog\n",
    "import fancylog as package\n",
    "\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from fcutils.file_io.io import load_yaml, save_yaml\n",
    "from fcutils.file_io.utils import check_create_folder, get_file_name\n",
    "\n",
    "from movie_visualizer import compare_videos\n",
    "from utils import start_server, load_params, add_to_params_dict\n",
    "\n",
    "c, dview, n_processes = start_server()\n",
    "\n",
    "from IPython.display import clear_output\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get file paths\n",
    "Get the path of the video to motion correct. Need to have done preprocessing first and have specified in `analysis_metadata.yml` which video to use for motion correction."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files to process\n",
    "fld = 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05' # <- which folder/recording we are working on\n",
    "metadata = load_yaml(os.path.join(fld, \"01_PARAMS\", \"analysis_metadata.yml\"))\n",
    "\n",
    "\n",
    "if not 'video_for_mc' in metadata.keys() or metadata['video_for_mc'] is None:\n",
    "    raise ValueError(\"Do preprocessing first\")\n",
    "\n",
    "vid_to_correct = os.path.join(fld, metadata[metadata['video_for_mc']])\n",
    "if not os.path.isfile(vid_to_correct):\n",
    "    raise ValueError(f\"The file you want to use for correction doesn't exist: {vid_to_correct}\")\n",
    "\n",
    "fnames    = [vid_to_correct]  # video to processprocessed\n",
    "base_name = pathlib.Path(fnames[0]).stem # used to save mmepped data\n",
    "\n",
    "output_fld = os.path.join(fld, metadata['outputfld']) # plots and other stuff will be saved here\n",
    "check_create_folder(output_fld)\n",
    "\n",
    "videos = {'raw': os.path.join(metadata['fld'], metadata['ffcsub_video'])} # use this to store paths to videos generated during analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up MC params\n",
    "\n",
    "Each session's parameters are saved in fld > 01_PARAMS > params.yml"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Starting logging\n2020-04-18 17:03:39 PM - INFO - MainProcess fancylog.py:271 - Starting logging\nINFO:root:Multiprocessing-logging module not found, not logging multiple processes.\n2020-04-18 17:03:39 PM - INFO - MainProcess fancylog.py:273 - Multiprocessing-logging module not found, not logging multiple processes.\nINFO:root:ANALYSIS METADATA FILE:\n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:21 - ANALYSIS METADATA FILE:\nINFO:root:experimenter:  Federico\n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:23 - experimenter:  Federico\nINFO:root:fld:  D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:23 - fld:  D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\nINFO:root:outputfld:  MC_output_crop_downscale\n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:23 - outputfld:  MC_output_crop_downscale\nINFO:root:raw_video:  19JUN05_BF164p1_v1_ds126_crop_raw.tif\n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:23 - raw_video:  19JUN05_BF164p1_v1_ds126_crop_raw.tif\nINFO:root:ffcsub_video:  19JUN05_BF164p1_v1_ds126_crop_ffcSub.tiff\n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:23 - ffcsub_video:  19JUN05_BF164p1_v1_ds126_crop_ffcSub.tiff\nINFO:root:ffcsub_params:  {'downscaling': 0.2, 'sigma': 25, 'mean': 'movie_mean', 'norm_by': 'subtraction'}\n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:23 - ffcsub_params:  {'downscaling': 0.2, 'sigma': 25, 'mean': 'movie_mean', 'norm_by': 'subtraction'}\nINFO:root:fft_bandpass_params:  [{'large_structures': 80}, {'small_structures': 5}, {'suppress_stripes': 'None'}, {'autoscale': True}, {'saturate': False}, {'display': False}]\n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:23 - fft_bandpass_params:  [{'large_structures': 80}, {'small_structures': 5}, {'suppress_stripes': 'None'}, {'autoscale': True}, {'saturate': False}, {'display': False}]\nINFO:root:fftfilt_video:  19JUN05_BF164p1_v1_ds126_crop_ffcSub_fftfilt.tif\n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:23 - fftfilt_video:  19JUN05_BF164p1_v1_ds126_crop_ffcSub_fftfilt.tif\nINFO:root:norm_by_fft_video:  19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft.tif\n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:23 - norm_by_fft_video:  19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft.tif\nINFO:root:video_for_mc:  norm_by_fft_video\n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:23 - video_for_mc:  norm_by_fft_video\nINFO:root:transformed_mc_video:  \n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:23 - transformed_mc_video:  \nINFO:root:raw_mc_video:  \n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:23 - raw_mc_video:  \nINFO:root:video_for_cnmfe_fit:  raw_mc_video\n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:23 - video_for_cnmfe_fit:  raw_mc_video\nINFO:root:components_qc_params:  {'filter_by_size': True, 'remove_duplicate_components': True}\n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:23 - components_qc_params:  {'filter_by_size': True, 'remove_duplicate_components': True}\nINFO:root:Output folder: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\MC_output_crop_downscale\n2020-04-18 17:03:39 PM - INFO - MainProcess <ipython-input-3-f4128f1d81a6>:24 - Output folder: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\MC_output_crop_downscale\n"
    }
   ],
   "source": [
    "# dataset dependent parameters\n",
    "frate = 10.                       # movie frame rate\n",
    "decay_time = 2.              # length of a typical transient in seconds\n",
    "\n",
    "\n",
    "# Load recording specific params and fill them up\n",
    "prms = load_params(fld)['motion_correction']\n",
    "prms = add_to_params_dict(prms, fnames=fnames, fr=frate, decay_time=decay_time)\n",
    "\n",
    "\n",
    "opts = params.CNMFParams(params_dict=prms)\n",
    "\n",
    "\n",
    "# Setup logging\n",
    "logging_file = fancylog.start_logging(os.path.join(fld, \"02_LOGS\"), package, file_log_level=\"INFO\", variables=[opts], verbose=False, filename='motion_correction_logs')\n",
    "\n",
    "with open( os.path.join(output_fld, \"log_file_path.txt\"), \"w+\") as t: # save in the output folder path to log file\n",
    "    t.write(logging_file)\n",
    "\n",
    "# Write down metadata about analysis\n",
    "logging.info(\"ANALYSIS METADATA FILE:\")\n",
    "for k,v in metadata.items():\n",
    "    logging.info(f\"{k}:  {v}\")\n",
    "logging.info(f\"Output folder: {output_fld}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Correction\n",
    "The background signal in micro-endoscopic data is very strong and makes the motion correction challenging. \n",
    "As a first step the algorithm performs a high pass spatial filtering with a Gaussian kernel to remove the bulk of the background and enhance spatial landmarks. \n",
    "The size of the kernel is given from the parameter `gSig_filt`. If this is left to the default value of `None` then no spatial filtering is performed (default option, used in 2p data).\n",
    "After spatial filtering, the NoRMCorre algorithm is used to determine the motion in each frame. The inferred motion is then applied to the *original* data so no information is lost.\n",
    "\n",
    "\n",
    "After the motion correction shifts are computed on the transformed and normalized videos, they are used to motion correct the raw video. This is so that the raw, motion corrected, video can be used for quality evaluation and for CNMF-E fitting. Generally motion correction will be computed on a transformed variant of the raw video (e.g. fft bandpass filtered or normalized), but for signal extraction or evaluating the quality of the MC one might want to look at the raw video motion corrected. To do that, the shifts computed on the transformed video will be applied to the raw video, so that that too is motion corrected\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rigid motion correction\n",
    "### Compute shifts"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Starting rigid mc: 1 iterations.\n2020-04-18 17:03:40 PM - INFO - MainProcess <ipython-input-4-babe6ea3cd2e>:1 - Starting rigid mc: 1 iterations.\nINFO:root:Saving file as D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft_rig__d1_109_d2_92_d3_1_order_F_frames_22662_.mmap\n2020-04-18 17:03:40 PM - INFO - MainProcess motion_correction.py:3017 - Saving file as D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft_rig__d1_109_d2_92_d3_1_order_F_frames_22662_.mmap\nINFO:root:** Starting parallel motion correction **\n2020-04-18 17:03:40 PM - INFO - MainProcess motion_correction.py:3030 - ** Starting parallel motion correction **\nINFO:root:** Finished parallel motion correction **\n2020-04-18 17:04:58 PM - INFO - MainProcess motion_correction.py:3038 - ** Finished parallel motion correction **\nINFO:root:Rigid motion corrected video was saved at:\n D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft_rig__d1_109_d2_92_d3_1_order_C_frames_22662_.mmap\n2020-04-18 17:05:06 PM - INFO - MainProcess <ipython-input-4-babe6ea3cd2e>:14 - Rigid motion corrected video was saved at:\n D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft_rig__d1_109_d2_92_d3_1_order_C_frames_22662_.mmap\n"
    }
   ],
   "source": [
    "logging.info(f\"Starting rigid mc: {prms['niter_rig']} iterations.\")\n",
    "\n",
    "mc = MotionCorrect(fnames, dview=dview, **opts.get_group('motion'))\n",
    "\n",
    "# correct for rigid motion correction and save the file (in memory mapped form)\n",
    "_ = mc.motion_correct(save_movie=True)\n",
    "\n",
    "# Now save in C order for CNMF-E \n",
    "bord_px = 0\n",
    "bord_px = 0 if prms['border_nan'] is 'copy' else bord_px\n",
    "motioncorrected = cm.mmapping.save_memmap(mc.mmap_file, base_name=base_name+\"_rig_\", order='C', border_to_0=bord_px)\n",
    "videos['transf_rig_mc'] = motioncorrected\n",
    "\n",
    "logging.info(f\"Rigid motion corrected video was saved at:\\n {motioncorrected}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply shifts to raw video"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Applying shifts to ffcsub (not normalized) video: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub.tiff\n2020-04-18 17:05:07 PM - INFO - MainProcess <ipython-input-5-888702039146>:4 - Applying shifts to ffcsub (not normalized) video: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub.tiff\nINFO:root:Saved motion corrected raw video as: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_rig_d1_109_d2_92_d3_1_order_F_frames_22662_.mmap\n\n2020-04-18 17:05:25 PM - INFO - MainProcess <ipython-input-5-888702039146>:7 - Saved motion corrected raw video as: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_rig_d1_109_d2_92_d3_1_order_F_frames_22662_.mmap\n\nINFO:root:Saved motion corrected raw video (C order) as: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_rig_d1_109_d2_92_d3_1_order_C_frames_22662_.mmap\n\n2020-04-18 17:05:34 PM - INFO - MainProcess <ipython-input-5-888702039146>:12 - Saved motion corrected raw video (C order) as: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_rig_d1_109_d2_92_d3_1_order_C_frames_22662_.mmap\n\n"
    }
   ],
   "source": [
    "apply_to = os.path.join(metadata['fld'], metadata['ffcsub_video'])\n",
    "apply_to_base_name = os.path.join(fld, pathlib.Path(apply_to).stem+\"_rig\") # used to save mmepped data\n",
    "\n",
    "logging.info(f\"Applying shifts to ffcsub (not normalized) video: {apply_to}\")\n",
    "\n",
    "raw_mc_filepath_F = mc.apply_shifts_movie(apply_to, save_memmap=True, save_base_name=apply_to_base_name, order=\"F\", remove_min=True)\n",
    "logging.info(f\"Saved motion corrected raw video as: {raw_mc_filepath_F}\\n\")\n",
    "\n",
    "# Now save in C order\n",
    "raw_motioncorrected = cm.mmapping.save_memmap([raw_mc_filepath_F], base_name=apply_to_base_name, order='C', border_to_0=bord_px)\n",
    "videos['raw_rig_mc'] = raw_motioncorrected\n",
    "logging.info(f\"Saved motion corrected raw video (C order) as: {raw_motioncorrected}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Piecewise rigid motion correction\n",
    "### Compute shifts"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Saving file as D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft_els__d1_109_d2_92_d3_1_order_F_frames_22662_.mmap\n2020-04-18 17:05:35 PM - INFO - MainProcess motion_correction.py:3017 - Saving file as D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft_els__d1_109_d2_92_d3_1_order_F_frames_22662_.mmap\nINFO:root:** Starting parallel motion correction **\n2020-04-18 17:05:35 PM - INFO - MainProcess motion_correction.py:3030 - ** Starting parallel motion correction **\nINFO:root:** Finished parallel motion correction **\n2020-04-18 17:06:43 PM - INFO - MainProcess motion_correction.py:3038 - ** Finished parallel motion correction **\nINFO:root:Piecewise motion corrected video was saved at:\n D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft_els__d1_109_d2_92_d3_1_order_C_frames_22662_.mmap\n2020-04-18 17:06:53 PM - INFO - MainProcess <ipython-input-6-df6d7b13a51d>:11 - Piecewise motion corrected video was saved at:\n D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft_els__d1_109_d2_92_d3_1_order_C_frames_22662_.mmap\n"
    }
   ],
   "source": [
    "# motion correct piecewise rigid\n",
    "mc.pw_rigid = True  # turn the flag to True for pw-rigid motion correction\n",
    "mc.template = mc.mmap_file  # use the results of the rigid motion corrction to save in computation\n",
    "_ = mc.motion_correct(save_movie=True, template=mc.total_template_rig)\n",
    "\n",
    "# Now save in C order for CNMF-E \n",
    "bord_px = 0 if prms['border_nan'] is 'copy' else bord_px\n",
    "pw_motioncorrected = cm.mmapping.save_memmap(mc.mmap_file, base_name=base_name+\"_els_\", order='C', border_to_0=bord_px)\n",
    "videos['transf_pw_mc'] = pw_motioncorrected\n",
    "\n",
    "logging.info(f\"Piecewise motion corrected video was saved at:\\n {pw_motioncorrected}\")\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply shifts to raw video"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Applying shifts to ffcsub (not normalized) video: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub.tiff\n2020-04-18 17:06:53 PM - INFO - MainProcess <ipython-input-7-510b9cbc6680>:4 - Applying shifts to ffcsub (not normalized) video: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub.tiff\nINFO:root:Saved motion corrected raw video as: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_els_d1_109_d2_92_d3_1_order_F_frames_22662_.mmap\n\n2020-04-18 17:07:04 PM - INFO - MainProcess <ipython-input-7-510b9cbc6680>:7 - Saved motion corrected raw video as: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_els_d1_109_d2_92_d3_1_order_F_frames_22662_.mmap\n\nINFO:root:Saved motion corrected raw video (C order) as: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_els_d1_109_d2_92_d3_1_order_C_frames_22662_.mmap\n\n2020-04-18 17:07:13 PM - INFO - MainProcess <ipython-input-7-510b9cbc6680>:12 - Saved motion corrected raw video (C order) as: D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_els_d1_109_d2_92_d3_1_order_C_frames_22662_.mmap\n\n"
    }
   ],
   "source": [
    "apply_to = os.path.join(metadata['fld'], metadata['ffcsub_video'])\n",
    "apply_to_base_name = os.path.join(fld, pathlib.Path(apply_to).stem+\"_els\") # used to save mmepped data\n",
    "\n",
    "logging.info(f\"Applying shifts to ffcsub (not normalized) video: {apply_to}\")\n",
    "\n",
    "raw_mc_els_filepath_F = mc.apply_shifts_movie(apply_to, save_memmap=True, save_base_name=apply_to_base_name, order=\"F\", remove_min=True)\n",
    "logging.info(f\"Saved motion corrected raw video as: {raw_mc_els_filepath_F}\\n\")\n",
    "\n",
    "# Now save in C order\n",
    "raw_pw_motioncorrected = cm.mmapping.save_memmap([raw_mc_els_filepath_F], base_name=apply_to_base_name, order='C', border_to_0=bord_px)\n",
    "videos['raw_pw_mc'] = raw_pw_motioncorrected\n",
    "logging.info(f\"Saved motion corrected raw video (C order) as: {raw_pw_motioncorrected}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End\n",
    "Save a couple things that will be useful for the next few steps and you're done. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:VIDEOS: {'raw': 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\\\\19JUN05_BF164p1_v1_ds126_crop_ffcSub.tiff', 'transf_rig_mc': 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\\\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft_rig__d1_109_d2_92_d3_1_order_C_frames_22662_.mmap', 'raw_rig_mc': 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\\\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_rig_d1_109_d2_92_d3_1_order_C_frames_22662_.mmap', 'transf_pw_mc': 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\\\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft_els__d1_109_d2_92_d3_1_order_C_frames_22662_.mmap', 'raw_pw_mc': 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\\\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_els_d1_109_d2_92_d3_1_order_C_frames_22662_.mmap'}\n2020-04-18 17:07:14 PM - INFO - MainProcess <ipython-input-8-d25d3c3b3f9a>:4 - VIDEOS: {'raw': 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\\\\19JUN05_BF164p1_v1_ds126_crop_ffcSub.tiff', 'transf_rig_mc': 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\\\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft_rig__d1_109_d2_92_d3_1_order_C_frames_22662_.mmap', 'raw_rig_mc': 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\\\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_rig_d1_109_d2_92_d3_1_order_C_frames_22662_.mmap', 'transf_pw_mc': 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\\\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_div_fft_els__d1_109_d2_92_d3_1_order_C_frames_22662_.mmap', 'raw_pw_mc': 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\\\\19JUN05_BF164p1_v1_ds126_crop_ffcSub_els_d1_109_d2_92_d3_1_order_C_frames_22662_.mmap'}\nINFO:root:Saving video paths at D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\MC_output_crop_downscale\\video_paths.yml\n2020-04-18 17:07:14 PM - INFO - MainProcess <ipython-input-8-d25d3c3b3f9a>:5 - Saving video paths at D:\\Dropbox (UCL - SWC)\\Project_vgatPAG\\analysis\\doric\\BF164p1\\19JUN05\\MC_output_crop_downscale\\video_paths.yml\n"
    }
   ],
   "source": [
    "savepath = os.path.join(output_fld, \"video_paths.yml\")\n",
    "save_yaml(savepath, videos)\n",
    "\n",
    "logging.info(f\"VIDEOS: {videos}\")\n",
    "logging.info(f\"Saving video paths at {savepath}\")\n",
    ""
   ]
  }
 ]
}