{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python361064bitcaiconda8c51914467a4460685b7f212a4ce3dd5",
   "display_name": "Python 3.6.10 64-bit ('cai': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect/Visualise CNFM-E fit to motion corrected data\n",
    "\n",
    "This notebook is used mainly to curate the components found by CNMF-E. \n",
    "The first curation steps are automated and use some of caiman's code, after that is manual curation where components can be merged or eliminated.  "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    get_ipython().magic(u'load_ext autoreload')\n",
    "    get_ipython().magic(u'autoreload 2')\n",
    "    get_ipython().magic(u'matplotlib qt')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import napari\n",
    "\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.source_extraction.cnmf.spatial import threshold_components\n",
    "from caiman.utils.visualization import inspect_correlation_pnr\n",
    "\n",
    "import logging\n",
    "from fancylog import fancylog\n",
    "import fancylog as package\n",
    "\n",
    "import cv2\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "import bokeh.plotting as bpl\n",
    "\n",
    "from fcutils.file_io.io import load_yaml\n",
    "from fcutils.video.utils import open_cvwriter, get_cap_from_images_folder, save_videocap_to_video\n",
    "from fcutils.plotting.utils import clean_axes, save_figure, add_colorbar_to_img\n",
    "\n",
    "from utils import print_cnmfe_components, plot_components_over_image, load_fit_cnmfe\n",
    "from utils import start_server, load_params,  log_cnmfe_components, load_mmap_video_caiman\n",
    "\n",
    "bpl.output_notebook()\n",
    "c, dview, n_processes = start_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata, model and data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "fld = 'D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p2\\\\19JUN26'\n",
    "metadata = load_yaml(os.path.join(fld, \"01_PARAMS\", \"analysis_metadata.yml\"))\n",
    "\n",
    "# Load video\n",
    "video = os.path.join(fld, metadata[metadata['video_for_cnmfe_fit']])\n",
    "Yr, dims, T, images = load_mmap_video_caiman(video)\n",
    "bg = np.max(images, axis=0)\n",
    "\n",
    "\n",
    "# Load model\n",
    "cnm, model_filepath = load_fit_cnmfe(fld, n_processes, dview)\n",
    "\n",
    "# Start logging\n",
    "fancylog.start_logging(os.path.join(fld, \"02_LOGS\"), package, file_log_level=\"INFO\", variables=[cnm.params], verbose=True,    filename='cnmfe_component_inspection_logs')\n",
    "logging.info(\"Starting CNMF-E component inspection\")\n",
    "\n",
    "# Add analysis metadata to log\n",
    "logging.info(\"ANALYSIS METADATA FILE:\")\n",
    "for k,v in metadata.items():\n",
    "    logging.info(f\"{k}: {v}\")\n",
    "\n",
    "logging.info(f\"Video used for CNMF-E fitting: {metadata['video_for_cnmfe_fit']}: {video}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect components\n",
    "\n",
    "Apply a number of quality controls of the components to keep only the good stuff.\n",
    "Quality control steps include:\n",
    "\n",
    "    - evaluate components \n",
    "    - threshold spatial components -> remove duplicates\n",
    "    - remove small/large components [currently not implemented]\n",
    "\n",
    "there's no undo for these operations, so if you need to restart from scratch you'll need\n",
    "to re load cnm (or fit a new one even):\n",
    "\n",
    "    cnm = load_fit_cnfm(model_path, n_processes, dview)\n",
    "\n",
    "To check the params used for quality check use:\n",
    "\n",
    "    cnm.params.quality\n",
    "\n",
    "## Automatic quality evaluation"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at what things are like to start with\n",
    "print_cnmfe_components(cnm, msg=\"Before quality control:\")\n",
    "log_cnmfe_components(cnm,  msg=\"Before quality control\")\n",
    "\n",
    "# Estimate\n",
    "cnm.estimates.evaluate_components(images, cnm.params, dview=dview)\n",
    "coordinates = cm.utils.visualization.get_contours(cnm.estimates.A, bg.shape, thr=.2, thr_method=\"max\")\n",
    "good_compontents = cnm.estimates.idx_components\n",
    "\n",
    "# log\n",
    "print_cnmfe_components(cnm, msg=\"After evaluate components\")\n",
    "log_cnmfe_components(cnm,  msg=\"After evaluate components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove overlapping components\n",
    "and components that are either too small ar too big"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate spatial components\n",
    "cnm.estimates.dims = dims\n",
    "cnm.estimates.threshold_spatial_components(dview=dview)\n",
    "\n",
    "\n",
    "if metadata['components_qc_params']['filter_by_size']:\n",
    "    logging.info(\"Filtering components based on size\")\n",
    "\n",
    "    # load params\n",
    "    _params = load_yaml(os.path.join(fld, \"01_params\", \"params.yml\"))['quality_evaluation_params']\n",
    "\n",
    "    # Remove large/small and duplicate neurons\n",
    "    cnm.estimates.remove_small_large_neurons(_params['min_size_neuro'], _params['max_size_neuro'])\n",
    "    print_cnmfe_components(cnm, msg=\"After filter by size\")\n",
    "    log_cnmfe_components(cnm,  msg=\"After filter by size\")\n",
    "\n",
    "if metadata['components_qc_params']['remove_duplicate_components']:\n",
    "    logging.info(\"Removing duplicates\")\n",
    "\n",
    "    _ = cnm.estimates.remove_duplicates(plot_duplicates=False)\n",
    "\n",
    "    print_cnmfe_components(cnm, msg=\"After Remove overlapping\")\n",
    "    log_cnmfe_components(cnm,  msg=\"After Remove overlapping\")\n",
    "\n",
    "coordinates = cm.utils.visualization.get_contours(cnm.estimates.A, bg.shape, thr=.2, thr_method=\"max\")\n",
    "good_compontents = cnm.estimates.idx_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Components location\n",
    "\n",
    "Visualise the location of good and bad components on the cn_filt image and the residual optic flow image"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise good/bad components over the residual optic flow image\n",
    "\n",
    "optflow_img_path = os.path.join(metadata['fld'], metadata['outputfld'], 'residual_opticflow_raw.npy')\n",
    "optflow_img = np.load(optflow_img_path)\n",
    "\n",
    "f, axarr = plt.subplots(figsize=(15, 10), ncols=2)\n",
    "for ax, only in zip(axarr, [\"good\", \"bad\"]):\n",
    "    img = plot_components_over_image(optflow_img, ax, coordinates, 2, good_compontents, cmap=\"viridis\", only=only)\n",
    "    add_colorbar_to_img(img, ax, f)\n",
    "\n",
    "axarr[0].set(title=\"GOOD components\")\n",
    "axarr[1].set(title=\"BAD components\")\n",
    "clean_axes(f)\n",
    "\n",
    "img_filepath = os.path.join(fld, \"components_not_curated_on_optflow\")\n",
    "save_figure(f, img_filepath)\n",
    "logging.info(f\"Saved image with contours at {img_filepath}\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize components over mean projection frame\n",
    "f, axarr = plt.subplots(figsize=(15, 10), ncols=2)\n",
    "for ax, only in zip(axarr, [\"good\", \"bad\"]):\n",
    "    img = plot_components_over_image(bg, ax, coordinates, 2, good_compontents, cmap=\"gray\", only=only)\n",
    "\n",
    "axarr[0].set(title=\"GOOD components\")\n",
    "axarr[1].set(title=\"BAD components\")\n",
    "clean_axes(f)\n",
    "\n",
    "img_filepath = os.path.join(fld, \"components_not_curated_on_meanproj\")\n",
    "save_figure(f, img_filepath)\n",
    "logging.info(f\"Saved image with contours at {img_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize components signal\n",
    "use `view_patches_bar` to view the location and the inferred trace for each component"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUAL COMPONENTS CURATION\n",
    "First some prep...\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_commands = []\n",
    "\n",
    "def get_component_idx(component_id):\n",
    "    if component_id not in [c['neuron_id'] for c in coordinates]:\n",
    "        raise ValueError(\"Invalid component\")\n",
    "    else:\n",
    "        return component_id - 1\n",
    "\n",
    "def plot_again():\n",
    "    # Visualize components over mean projection frame\n",
    "    bg = np.max(images, axis=0)\n",
    "\n",
    "\n",
    "    cnm.estimates.coordinates = cm.utils.visualization.get_contours(cnm.estimates.A, bg.shape, thr=.05, thr_method=\"max\")\n",
    "    coordinates = cnm.estimates.coordinates\n",
    "    good_compontents =cnm.estimates.idx_components\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(15, 10),)\n",
    "\n",
    "    img = plot_components_over_image(bg, ax, coordinates, 4, good_compontents, cmap=\"gray\", alpha=.6)\n",
    "    clean_axes(f)\n",
    "\n",
    "    img_filepath = os.path.join(fld, \"components_curated_on_meanproj\")\n",
    "    save_figure(f, img_filepath)\n",
    "    logging.info(f\"Saved image with contours at {img_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge components\n",
    "\n",
    "Manually merge components by specifying groups of components (using the numbers you see in the images above). Note that sometimes merging good components yields a bad one, so after that you'll have to manually specify which one is good and which one is bad"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_merge = [\n",
    "\n",
    "]\n",
    "\n",
    "for mergin in to_merge:\n",
    "    if not mergin: continue\n",
    "    merge_commands.append(mergin)\n",
    "    idxs = [get_component_idx(i) for i in mergin]\n",
    "    cnm.estimates.manual_merge(components=[idxs], params=cnm.params)\n",
    "\n",
    "\n",
    "# Estimate\n",
    "# cnm.estimates.evaluate_components(images, cnm.params, dview=dview)\n",
    "# cnm.estimates.threshold_spatial_components(dview=dview)\n",
    "print_cnmfe_components(cnm, msg=\"After evaluate components\")\n",
    "\n",
    "plot_again()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once happy with the mergin you can save the merge commands to file to avoid having to do it again manually if you need to"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### move from bad to good and vice versa\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_bad_to_good = [\n",
    "]\n",
    "\n",
    "from_good_to_bad = [\n",
    "]\n",
    "\n",
    "for btg in from_bad_to_good:\n",
    "    logging.info(f\"Moving component {btg} from bad to good\")\n",
    "    cnm.estimates.idx_components_bad = np.delete(cnm.estimates.idx_components_bad, np.argwhere(cnm.estimates.idx_components_bad == btg))\n",
    "    cnm.estimates.idx_components = np.append(cnm.estimates.idx_components, btg)\n",
    "\n",
    "for gtb in from_good_to_bad:\n",
    "    logging.info(f\"Moving component {gtb} from good to bad\")\n",
    "    cnm.estimates.idx_components_bad = cnm.estimates.idx_components = np.delete(cnm.estimates.idx_components, np.argwhere(cnm.estimates.idx_components == gtb))\n",
    "    np.append(cnm.estimates.idx_components_bad, gtb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save updated cnmfe model\n",
    "If you're happy with the results, you can save the model for further analysis\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_path = os.path.join(fld, \"cnmfe_fit_curated.hdf5\")\n",
    "cnm.save(new_model_path)\n",
    "logging.info(f\"Saving updated model at {new_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize components over videos and interactive plots\n",
    "\n",
    "Use the first cell if you just want to quickly look at the data, otherwise the next cell can be used to create a video but it's quite slow"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caiman.utils.visualization import view_patches_bar\n",
    "\n",
    "d1, d2 = bg.shape\n",
    "view_patches_bar(Yr, cnm.estimates.A, cnm.estimates.C, cnm.estimates.b, cnm.estimates.f, d1, d2, img=bg)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To quickly look at the data use this code\n",
    "SHOW_GOOD = True\n",
    "SHOW_BAD = False\n",
    "\n",
    "\n",
    "# Get contours from data\n",
    "coordinates = cm.utils.visualization.get_contours(cnm.estimates.A, cn_filter.shape, thr=.2, thr_method=\"max\")\n",
    "good_compontents = cnm.estimates.idx_components\n",
    "\n",
    "# prep contours for plotting\n",
    "good_coords = [c['coordinates'][1:-2, ::-1] for c in coordinates if c['neuron_id'] in good_compontents]\n",
    "good_coords = [c[~np.isnan(c).any(axis=1)] for c in good_coords] # remove nans\n",
    "good_coords = [np.vstack([c, c[0]]) for c in good_coords]\n",
    "\n",
    "bad_coords = [c['coordinates'][1:-2, ::-1] for c in coordinates if c['neuron_id'] not in good_compontents]\n",
    "bad_coords = [c[~np.isnan(c).any(axis=1)] for c in bad_coords] # remove nans\n",
    "bad_coords = [np.vstack([c, c[0]]) for c in bad_coords]\n",
    "\n",
    "# Napari viewer\n",
    "v = napari.Viewer(ndisplay=2)\n",
    "\n",
    "v.add_image(images, name=\"Signal\", colormap=\"gray\")\n",
    "\n",
    "# add good components\n",
    "if SHOW_GOOD:\n",
    "    layer = v.add_shapes(\n",
    "        good_coords,\n",
    "        shape_type='path',\n",
    "        edge_width=1,\n",
    "        edge_color='green',\n",
    "        opacity=.5,\n",
    "        face_color='royalblue',\n",
    "        name='GOOD',\n",
    "    )\n",
    "\n",
    "# add bad components\n",
    "if SHOW_BAD:\n",
    "    layer = v.add_shapes(\n",
    "        bad_coords,\n",
    "        shape_type='path',\n",
    "        edge_width=.8,\n",
    "        edge_color='red',\n",
    "        opacity=.3,\n",
    "        face_color='royalblue',\n",
    "        name='BAD',\n",
    "    )\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### video maker, very slow..."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_fld = \"D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\Fede\\\\frames\" # folder where frames will be saved before creating video\n",
    "\n",
    "\n",
    "tot_frames, w, h = images.shape\n",
    "frames = np.arange(0, tot_frames, 10)\n",
    "\n",
    "plt.ioff()\n",
    "print(f\"Creating video with {len(frames)} frames\")\n",
    "\n",
    "# Create an image for each frame and save it\n",
    "if TrFalse  # <-- !! Set this as true if you want to create the video, keeping it False to avoid doing this by accident as it's slow   for n, fnum in tqdm(enumerate(frames)):\n",
    "        f, ax = plt.subplots(figsize=(120, 100), dpi=5)\n",
    "        plot_components_over_image(images[fnum, :, :].copy(), ax, coordinates, 17, good_compontents)\n",
    "        f.savefig(os.path.join(frames_fld, f\"{n}\"), dpi=5)\n",
    "        plt.close()\n",
    "        \n",
    "plt.ion()\n",
    "\n",
    "# Stitch images into a video\n",
    "\"\"\" \n",
    "Use this ffmpeg command to stitch the frames inot a video\n",
    "\n",
    "first cd to the folder parent of the on where you saved the frames in. \n",
    "e.g. if you saved the frames here: D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\Fede\\\\frames\n",
    "then cd to: D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\Fede\n",
    "\n",
    "Then use:\n",
    "ffmpeg -i frames\\%1d.png -c:v libx264 -vf fps=10 -pix_fmt yuv420p out.mp4\n",
    "\n",
    "the video will be saved as D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\Fede\\\\out.mp4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}