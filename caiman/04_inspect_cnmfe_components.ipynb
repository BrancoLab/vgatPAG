{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python361064bitcaiconda8c51914467a4460685b7f212a4ce3dd5",
   "display_name": "Python 3.6.10 64-bit ('cai': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect/Visualise CNFM-E fit to motion corrected data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    get_ipython().magic(u'load_ext autoreload')\n",
    "    get_ipython().magic(u'autoreload 2')\n",
    "    get_ipython().magic(u'matplotlib qt')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import napari\n",
    "\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.source_extraction.cnmf.spatial import threshold_components\n",
    "from caiman.utils.visualization import inspect_correlation_pnr\n",
    "\n",
    "import logging\n",
    "from fancylog import fancylog\n",
    "import fancylog as package\n",
    "\n",
    "import cv2\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "import bokeh.plotting as bpl\n",
    "\n",
    "from fcutils.file_io.io import load_yaml\n",
    "from fcutils.video.utils import open_cvwriter, get_cap_from_images_folder, save_videocap_to_video\n",
    "from fcutils.plotting.utils import clean_axes, save_figure, add_colorbar_to_img\n",
    "\n",
    "from utils import print_cnmfe_components, plot_components_over_image, load_fit_cnmfe\n",
    "from utils import start_server, load_params,  log_cnmfe_components, load_mmap_video_caiman\n",
    "\n",
    "bpl.output_notebook()\n",
    "c, dview, n_processes = start_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata, model and data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fld = \"D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\"\n",
    "metadata = load_yaml(os.path.join(fld, \"01_PARAMS\", \"analysis_metadata.yml\"))\n",
    "\n",
    "# Load video\n",
    "video = os.path.join(fld, metadata[metadata['video_for_cnmfe_fit']])\n",
    "Yr, dims, T, images = load_mmap_video_caiman(video)\n",
    "\n",
    "# Load model\n",
    "cnm, model_filepath = load_fit_cnmfe(fld, n_processes, dview)\n",
    "\n",
    "\n",
    "# Get filtered and peak over noise ratio images\n",
    "cn_filter, pnr = cm.summary_images.correlation_pnr(images, gSig=cnm.params.init['gSig'][0], swap_dim=False)\n",
    "\n",
    "# Start logging\n",
    "fancylog.start_logging(os.path.join(fld, \"02_LOGS\"), package, file_log_level=\"INFO\", variables=[cnm.params], verbose=True,    filename='cnmfe_component_inspection_logs')\n",
    "logging.info(\"Starting CNMF-E component inspection\")\n",
    "\n",
    "# Add analysis metadata to log\n",
    "logging.info(\"ANALYSIS METADATA FILE:\")\n",
    "for k,v in metadata.items():\n",
    "    logging.info(f\"{k}: {v}\")\n",
    "\n",
    "logging.info(f\"Video used for CNMF-E fitting: {metadata['video_for_cnmfe_fit']}: {video}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect components\n",
    "\n",
    "Apply a number of quality controls of the components to keep only the good stuff.\n",
    "Quality control steps include:\n",
    "\n",
    "    - evaluate components \n",
    "    - threshold spatial components -> remove duplicates\n",
    "    - remove small/large components [currently not implemented]\n",
    "\n",
    "there's no undo for these operations, so if you need to restart from scratch you'll need\n",
    "to re load cnm:\n",
    "\n",
    "    cnm = load_fit_cnfm(model_path, n_processes, dview)\n",
    "\n",
    "To check the params used for quality check use:\n",
    "\n",
    "    cnm.params.quality"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at what things are like to start with\n",
    "cnm.params.quality\n",
    "print_cnmfe_components(cnm, msg=\"Before quality control:\")\n",
    "log_cnmfe_components(cnm,  msg=\"Before quality control\")\n",
    "\n",
    "\n",
    "# Estimate\n",
    "cnm.estimates.evaluate_components(images, cnm.params, dview=dview\n",
    "coordinates = cm.utils.visualization.get_contours(cnm.estimates.A, cn_filter.shape, thr=.2, thr_method=\"max\")\n",
    "good_compontents = cnm.estimates.idx_components)\n",
    "\n",
    "# log\n",
    "print_cnmfe_components(cnm, msg=\"After evaluate components\")\n",
    "log_cnmfe_components(cnm,  msg=\"After evaluate components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove overlapping components"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate spatial components\n",
    "cnm.estimates.dims = dims\n",
    "cnm.estimates.threshold_spatial_components(dview=dview)\n",
    "\n",
    "\n",
    "if metadata['components_qc_params']['filter_by_size']:\n",
    "    logging.info(\"Filtering components based on size\")\n",
    "\n",
    "    # load params\n",
    "    _params = load_yaml(os.path.join(fld, \"01_params\", \"params.yml\"))['quality_evaluation_params']\n",
    "\n",
    "    # Remove large/small and duplicate neurons\n",
    "    cnm.estimates.remove_small_large_neurons(_params['min_size_neuro'], _params['max_size_neuro'])\n",
    "    print_cnmfe_components(cnm, msg=\"After filter by size\")\n",
    "    log_cnmfe_components(cnm,  msg=\"After filter by size\")\n",
    "\n",
    "if metadata['components_qc_params']['remove_duplicate_components']:\n",
    "    logging.info(\"Removing duplicates\")\n",
    "\n",
    "    _ = cnm.estimates.remove_duplicates(plot_duplicates=False)\n",
    "\n",
    "    print_cnmfe_components(cnm, msg=\"After Remove overlapping\")\n",
    "    log_cnmfe_components(cnm,  msg=\"After Remove overlapping\")\n",
    "\n",
    "coordinates = cm.utils.visualization.get_contours(cnm.estimates.A, cn_filter.shape, thr=.2, thr_method=\"max\")\n",
    "good_compontents = cnm.estimates.idx_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Components location\n",
    "\n",
    "Visualise the location of good and bad components on the cn_filt image and the residual optic flow image"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise good/bad components over the cn_filter image\n",
    "f, axarr = plt.subplots(figsize=(15, 10), ncols=2)\n",
    "for ax, only in zip(axarr, [\"good\", \"bad\"]):\n",
    "    plot_components_over_image(cn_filter, ax, coordinates, 2, good_compontents, cmap=\"gray\", only=only)\n",
    "axarr[0].set(title=\"GOOD components\")\n",
    "axarr[1].set(title=\"BAD components\")\n",
    "clean_axes(f)\n",
    "\n",
    "img_filepath = os.path.join(fld, \"components_not_curated\")\n",
    "save_figure(f, img_filepath)\n",
    "logging.info(f\"Saved image with contours at {img_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise good/bad components over the residual optic flow image\n",
    "\n",
    "optflow_img_path = os.path.join(metadata['fld'], metadata['outputfld'], 'residual_opticflow_raw.npy')\n",
    "optflow_img = np.load(optflow_img_path)\n",
    "\n",
    "f, axarr = plt.subplots(figsize=(15, 10), ncols=2)\n",
    "for ax, only in zip(axarr, [\"good\", \"bad\"]):\n",
    "    img = plot_components_over_image(optflow_img, ax, coordinates, 2, good_compontents, cmap=\"viridis\", only=only)\n",
    "    add_colorbar_to_img(img, ax, f)\n",
    "\n",
    "axarr[0].set(title=\"GOOD components\")\n",
    "axarr[1].set(title=\"BAD components\")\n",
    "clean_axes(f)\n",
    "\n",
    "img_filepath = os.path.join(fld, \"components_not_curated_on_optflow\")\n",
    "save_figure(f, img_filepath)\n",
    "logging.info(f\"Saved image with contours at {img_filepath}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUAL COMPONENTS CURATION\n",
    "TODO..."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(figsize=(15, 10), ncols=2)\n",
    "for ax, im, ttl in zip(axarr, [cn_filter, cn_filter], [\"good\", \"bad\"]):\n",
    "    plot_components_over_image(im, ax, coordinates, 2, good_compontents, cmap=\"gray\", only=ttl)\n",
    "axarr[0].set(title=\"GOOD components\")\n",
    "axarr[1].set(title=\"BAD components\")\n",
    "clean_axes(f)\n",
    "\n",
    "img_filepath = os.path.join(fld, \"components_curated\")\n",
    "save_figure(f, img_filepath)\n",
    "logging.info(f\"Saved image with contours at {img_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save updated cnmfe model\n",
    "If you're happy with the results, you can save the model for further analysis\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_path = os.path.join(fld, \"cnmfe_fit_curated.hdf5\")\n",
    "cnm.save(new_model_path)\n",
    "logging.info(f\"Saving updated model at {new_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise components signal\n",
    "Create plots and videos to visualise the location and the signals and components"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if you want to look at bad components use: cnm.estimates.idx_components_bad instead of cnm.estimates.idx_components\n",
    "cnm.estimates.nb_view_components(img=cn_filter, \n",
    "                                idx=cnm.estimates.idx_components,\n",
    "                                denoised_color='red', \n",
    "                                cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make video with components over motion corrected data\n",
    "\n",
    "Use the first cell if you just want to quickly look at the data, otherwise the next cell can be used to create a video but it's quite slow"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To quickly look at the data use this code\n",
    "\n",
    "# Get contours \n",
    "good_coords = [c['coordinates'][1:-2, ::-1] for c in coordinates if c['neuron_id'] in good_compontents]\n",
    "good_coords = [c[~np.isnan(c).any(axis=1)] for c in good_coords] # remove nans\n",
    "good_coords = [np.vstack([c, c[0]]) for c in good_coords]\n",
    "\n",
    "bad_coords = [c['coordinates'][1:-2, ::-1] for c in coordinates if c['neuron_id'] not in good_compontents]\n",
    "bad_coords = [c[~np.isnan(c).any(axis=1)] for c in bad_coords] # remove nans\n",
    "bad_coords = [np.vstack([c, c[0]]) for c in bad_coords]\n",
    "\n",
    "# Napari viewer\n",
    "v = napari.Viewer(ndisplay=2)\n",
    "\n",
    "v.add_image(images, name=\"Signal\", colormap=\"gray\", contrast_limits=[340, 600])\n",
    "\n",
    "# add good components\n",
    "layer = v.add_shapes(\n",
    "    good_coords,\n",
    "    shape_type='path',\n",
    "    edge_width=0.5,\n",
    "    edge_color='green',\n",
    "    opacity=.5,\n",
    "    face_color='royalblue',\n",
    "    name='GOOD',\n",
    ")\n",
    "\n",
    "# add bad components\n",
    "layer = v.add_shapes(\n",
    "    bad_coords,\n",
    "    shape_type='path',\n",
    "    edge_width=0.15,\n",
    "    edge_color='red',\n",
    "    opacity=.3,\n",
    "    face_color='royalblue',\n",
    "    name='BAD',\n",
    ")\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_coords[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_fld = \"D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\Fede\\\\frames\" # folder where frames will be saved before creating video\n",
    "\n",
    "\n",
    "tot_frames, w, h = images.shape\n",
    "frames = np.arange(0, tot_frames, 10)\n",
    "\n",
    "plt.ioff()\n",
    "print(f\"Creating video with {len(frames)} frames\")\n",
    "\n",
    "# Create an image for each frame and save it\n",
    "if TrFalse  # <-- !! Set this as true if you want to create the video, keeping it False to avoid doing this by accident as it's slow   for n, fnum in tqdm(enumerate(frames)):\n",
    "        f, ax = plt.subplots(figsize=(120, 100), dpi=5)\n",
    "        plot_components_over_image(images[fnum, :, :].copy(), ax, coordinates, 17, good_compontents)\n",
    "        f.savefig(os.path.join(frames_fld, f\"{n}\"), dpi=5)\n",
    "        plt.close()\n",
    "        \n",
    "plt.ion()\n",
    "\n",
    "# Stitch images into a video\n",
    "\"\"\" \n",
    "Use this ffmpeg command to stitch the frames inot a video\n",
    "\n",
    "first cd to the folder parent of the on where you saved the frames in. \n",
    "e.g. if you saved the frames here: D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\Fede\\\\frames\n",
    "then cd to: D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\Fede\n",
    "\n",
    "Then use:\n",
    "ffmpeg -i frames\\%1d.png -c:v libx264 -vf fps=10 -pix_fmt yuv420p out.mp4\n",
    "\n",
    "the video will be saved as D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\Fede\\\\out.mp4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop cluster"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.stop_server(dview=dview)"
   ]
  }
 ]
}