{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python361064bitcaiconda8c51914467a4460685b7f212a4ce3dd5",
   "display_name": "Python 3.6.10 64-bit ('cai': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect/Visualise CNFM-E fit to motion corrected data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    get_ipython().magic(u'load_ext autoreload')\n",
    "    get_ipython().magic(u'autoreload 2')\n",
    "    get_ipython().magic(u'matplotlib qt')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.source_extraction.cnmf.spatial import threshold_components\n",
    "from caiman.utils.visualization import inspect_correlation_pnr\n",
    "\n",
    "import logging\n",
    "from fancylog import fancylog\n",
    "import fancylog as package\n",
    "\n",
    "\n",
    "import cv2\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "import bokeh.plotting as bpl\n",
    "\n",
    "from fcutils.video.utils import open_cvwriter, get_cap_from_images_folder, save_videocap_to_video\n",
    "from fcutils.plotting.utils import clean_axes, save_figure\n",
    "\n",
    "from utils import print_cnmfe_components, plot_components_over_image, load_fit_cnfm_and_data, load_fit_cnfm\n",
    "from utils import start_server, load_params,  log_cnmfe_components\n",
    "\n",
    "bpl.output_notebook()\n",
    "c, dview, n_processes = start_server()\n",
    "\n",
    "raise ValueError(\"add method to load metrics files and add contours on top of optic flow stuff\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load everything\n",
    "fld = \"D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\"\n",
    "cnm, model_filepath, Yr, dims, T, images, smooth_bg, cn_filter, pnr = load_fit_cnfm_and_data(fld, n_processes, dview, mc_type=\"els\")\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start logging\n",
    "fancylog.start_logging(os.path.join(fld, \"02_LOGS\"), package, file_log_level=\"INFO\", variables=[cnm.params], verbose=True,    filename='cnmfe_component_inspection_logs')\n",
    "logging.info(\"Starting CNMF-E component inspection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect components\n",
    "\n",
    "Apply a number of quality controls of the components to keep only the good stuff.\n",
    "Quality control steps include:\n",
    "\n",
    "    - evaluate components \n",
    "    - threshold spatial components -> remove duplicates\n",
    "    - remove small/large components [currently not implemented]\n",
    "\n",
    "there's no undo for these operations, so if you need to restart from scratch you'll need\n",
    "to re load cnm:\n",
    "\n",
    "    cnm = load_fit_cnfm(model_path, n_processes, dview)\n",
    "\n",
    "To check the params used for quality check use:\n",
    "\n",
    "    cnm.params.quality"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.params.quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cnmfe_components(cnm, msg=\"Before quality control:\")\n",
    "log_cnmfe_components(cnm,  msg=\"Before quality control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: https://github.com/flatironinstitute/CaImAn/blob/6c33118a5f55e5e178a0e18c896329f416ffef55/caiman/source_extraction/cnmf/estimates.py#L943\n",
    "\n",
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "# Update params     \n",
    "_params = load_params(fld)['cnmf_evalutaion']                   \n",
    "cnm.params.set('quality', _params)\n",
    "\n",
    "logging.info(f\"Components quality estimation, params: {_params}\")\n",
    "\n",
    "# Estimate\n",
    "cnm.estimates.evaluate_components(images, cnm.params, dview=dview)\n",
    "\n",
    "# log\n",
    "print_cnmfe_components(cnm, msg=\"After evaluate components\")\n",
    "log_cnmfe_components(cnm,  msg=\"After evaluate components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove overlapping components"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate spatial components\n",
    "cnm.estimates.dims = dims\n",
    "cnm.estimates.threshold_spatial_components(dview=dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove large/small and duplicate neurons\n",
    "# cnm.estimates.remove_small_large_neurons()\n",
    "# _ = cnm.estimates.remove_duplicates(plot_duplicates=False)\n",
    "\n",
    "# print_cnmfe_components(cnm, msg=\"After Remove overlapping\")\n",
    "# log_cnmfe_components(cnm,  msg=\"After Remove overlapping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Components location"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise good/bad components over the cn_filter image\n",
    "coordinates = cm.utils.visualization.get_contours(cnm.estimates.A, smooth_bg.shape, thr=.2, thr_method=\"max\")\n",
    "good_compontents = cnm.estimates.idx_components\n",
    "\n",
    "f, axarr = plt.subplots(figsize=(15, 10), ncols=2)\n",
    "for ax, im, ttl in zip(axarr, [cn_filter, cn_filter], [\"good\", \"bad\"]):\n",
    "    plot_components_over_image(im, ax, coordinates, 2, good_compontents, cmap=\"gray\", only=ttl)\n",
    "axarr[0].set(title=\"GOOD components\")\n",
    "axarr[1].set(title=\"BAD components\")\n",
    "clean_axes(f)\n",
    "\n",
    "img_filepath = os.path.join(fld, \"components_not_curated\")\n",
    "save_figure(f, img_filepath)\n",
    "logging.info(f\"Saved image with contours at {img_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUAL COMPONENTS CURATION\n",
    "TODO..."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot again contours of components to compare with earlier results\n",
    "coordinates = cm.utils.visualization.get_contours(cnm.estimates.A, smooth_bg.shape, thr=.2, thr_method=\"max\")\n",
    "good_compontents = cnm.estimates.idx_components\n",
    "\n",
    "f, axarr = plt.subplots(figsize=(15, 10), ncols=2)\n",
    "for ax, im, ttl in zip(axarr, [cn_filter, cn_filter], [\"good\", \"bad\"]):\n",
    "    plot_components_over_image(im, ax, coordinates, 2, good_compontents, cmap=\"gray\", only=ttl)\n",
    "axarr[0].set(title=\"GOOD components\")\n",
    "axarr[1].set(title=\"BAD components\")\n",
    "clean_axes(f)\n",
    "\n",
    "img_filepath = os.path.join(fld, \"components_curated\")\n",
    "save_figure(f, img_filepath)\n",
    "logging.info(f\"Saved image with contours at {img_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save updated cnmfe model\n",
    "If you're happy with the results, you can save the model for further analysis\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_path = os.path.join(fld, \"cnmfe_fit_curated.hdf5\")\n",
    "cnm.save(new_model_path)\n",
    "logging.info(f\"Saving updated model at {new_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise components signal\n",
    "Create plots and videos to visualise the location and the signals and components"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if you want to look at bad components use: cnm.estimates.idx_components_bad instead of cnm.estimates.idx_components\n",
    "cnm.estimates.nb_view_components(img=cn_filter, \n",
    "                                idx=cnm.estimates.idx_components,\n",
    "                                denoised_color='red', \n",
    "                                cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make video with components over motion corrected data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_fld = \"D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\Fede\\\\frames\" # folder where frames will be saved before creating video\n",
    "\n",
    "\n",
    "tot_frames, w, h = images.shape\n",
    "frames = np.arange(0, tot_frames, 100)\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "# Create an image for each frame and save it\n",
    "if True:\n",
    "    for n, fnum in tqdm(enumerate(frames)):\n",
    "        f, ax = plt.subplots(figsize=(120, 100), dpi=5)\n",
    "        img = cv2.filter2D(images[fnum, :, :].copy(), -1, kernel/121)\n",
    "        plot_components_over_image(img/smooth_bg, ax, coordinates, 17)\n",
    "        f.savefig(os.path.join(fld, f\"{n}\"), dpi=5)\n",
    "        plt.close()\n",
    "        \n",
    "plt.ion()\n",
    "\n",
    "# Stitch images into a video\n",
    "\"\"\" \n",
    "run this in ffmpeg from the correct folder to get the video out\n",
    "\n",
    "ffmpeg -i frames\\%1d.png -c:v libx264 -vf fps=10 -pix_fmt yuv420p out.mp4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop cluster"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.stop_server(dview=dview)"
   ]
  }
 ]
}