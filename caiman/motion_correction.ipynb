{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python361064bitcaiconda8c51914467a4460685b7f212a4ce3dd5",
   "display_name": "Python 3.6.10 64-bit ('cai': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Correction using the NoRMCorre algorithm\n",
    "\n",
    "Can use both rigid and piecewise motion correction. The original motion correction algorithm is described in this paper:\n",
    "https://www.sciencedirect.com/science/article/pii/S0165027017302753?via%3Dihub\n",
    "\n",
    "More details and tips here: https://caiman.readthedocs.io/en/master/CaImAn_Tips.html#motion-correction-tips\n",
    "\n",
    "And an example pipeline here:  https://github.com/flatironinstitute/CaImAn/blob/6c5c3b6117b71b6e8b44f62fc26fd3b3d914de12/demos/notebooks/demo_motion_correction.ipynb"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    get_ipython().magic(u'load_ext autoreload')\n",
    "    get_ipython().magic(u'autoreload 2')\n",
    "    get_ipython().magic(u'matplotlib qt')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "from shutil import copyfile\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.visualization import inspect_correlation_pnr\n",
    "\n",
    "import logging\n",
    "from fancylog import fancylog\n",
    "import fancylog as package\n",
    "\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "import bokeh.plotting as bpl\n",
    "\n",
    "from fcutils.file_io.utils import check_create_folder, get_file_name\n",
    "from fcutils.plotting.utils import clean_axes, save_figure\n",
    "from fcutils.plotting.colors import *\n",
    "\n",
    "from movie_visualizer import compare_videos\n",
    "from utils import start_server, load_params, add_to_params_dict\n",
    "\n",
    "bpl.output_notebook()\n",
    "\n",
    "c, dview, n_processes = start_server()\n",
    "\n",
    "from IPython.display import clear_output\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get file paths"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files to process\n",
    "fld = \"D:\\\\Dropbox (UCL - SWC)\\\\Project_vgatPAG\\\\analysis\\\\doric\\\\BF164p1\\\\19JUN05\" # main data folder\n",
    "\n",
    "fnames    = [os.path.join(fld, '19JUN05_BF164p1_v1_ds126_crop_ffcSub.tiff')]  # video to processprocessed\n",
    "base_name = pathlib.Path(fnames[0]).stem # used to save mmepped data\n",
    "\n",
    "output_fld = os.path.join(fld, \"MC_output3\") # plots and other stuff will be saved here\n",
    "check_create_folder(output_fld)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up MC params\n",
    "\n",
    "Each session's parameters are saved in fld > 01_PARAMS > params.yml"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "frate = 10.                       # movie frame rate\n",
    "decay_time = 2.              # length of a typical transient in seconds\n",
    "\n",
    "\n",
    "# Load recording specific params and fill them up\n",
    "prms = load_params(fld)['motion_correction']\n",
    "prms = add_to_params_dict(prms, fnames=fnames, fr=frate, decay_time=decay_time)\n",
    "\n",
    "\n",
    "opts = params.CNMFParams(params_dict=prms)\n",
    "\n",
    "\n",
    "# Setup logging\n",
    "logging_file = fancylog.start_logging(os.path.join(fld, \"02_LOGS\"), package, file_log_level=\"INFO\", variables=[opts], verbose=False, filename='motion_correction_logs')\n",
    "\n",
    "with open( os.path.join(output_fld, \"log_file_path.txt\"), \"w+\") as t:\n",
    "    t.write(logging_file)\n",
    "\n",
    "logging.info(\"Starting motion correction\")\n",
    "logging.info(f\"Output folder: {output_fld}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Correction\n",
    "The background signal in micro-endoscopic data is very strong and makes the motion correction challenging. \n",
    "As a first step the algorithm performs a high pass spatial filtering with a Gaussian kernel to remove the bulk of the background and enhance spatial landmarks. \n",
    "The size of the kernel is given from the parameter `gSig_filt`. If this is left to the default value of `None` then no spatial filtering is performed (default option, used in 2p data).\n",
    "After spatial filtering, the NoRMCorre algorithm is used to determine the motion in each frame. The inferred motion is then applied to the *original* data so no information is lost.\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rigid motion correction"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "mc = MotionCorrect(fnames, dview=dview, **opts.get_group('motion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# correct for rigid motion correction and save the file (in memory mapped form)\n",
    "_ = mc.motion_correct(save_movie=True)\n",
    "\n",
    "# Now save in C order for CNMF-E \n",
    "bord_px = 0\n",
    "bord_px = 0 if prms['border_nan'] is 'copy' else bord_px\n",
    "fname_new = cm.mmapping.save_memmap(mc.mmap_file, base_name=base_name+\"_rig_\", order='C', border_to_0=bord_px)\n",
    "\n",
    "\n",
    "logging.info(f\"Rigid motion corrected video was saved at:\\n {fname_new}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piecewise rigid motion correction"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# motion correct piecewise rigid\n",
    "mc.pw_rigid = True  # turn the flag to True for pw-rigid motion correction\n",
    "mc.template = mc.mmap_file  # use the results of the rigid motion corrction to save in computation\n",
    "_ = mc.motion_correct(save_movie=True, template=mc.total_template_rig)\n",
    "\n",
    "# Now save in C order for CNMF-E \n",
    "bord_px = 0 if prms['border_nan'] is 'copy' else bord_px\n",
    "fname_new_els = cm.mmapping.save_memmap(mc.mmap_file, base_name=base_name+\"_els_\", order='C', border_to_0=bord_px)\n",
    "\n",
    "logging.info(f\"Piecewise motion corrected video was saved at:\\n {fname_new_els}\")\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC quality evaluation\n",
    "\n",
    "Visualize the results in plots and video and compute metrics to quantify the quality of the motion correction.\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_TYPE = \"els\" # els or rigid mc\n",
    "if MC_TYPE == \"els\":\n",
    "    eval_video = fname_new_els \n",
    "else:\n",
    "    eval_video = fname_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load motion corrected movie\n",
    "m_rig = cm.load(eval_video)\n",
    "\n",
    "# visualize templates\n",
    "plt.figure(figsize = (20,10))\n",
    "_ = plt.imshow(mc.total_template_rig, cmap = 'gray')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at correlation and PNR in motion corrected movie\n",
    "\n",
    "You can use this to find the correct values for `min_corr` and `min_pnr` values for cnmf fitting."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load memmapped motion corrected video\n",
    "Yr, dims, T = cm.load_memmap(fname_new_els)\n",
    "images = Yr.T.reshape((T,) + dims, order='F')\n",
    "\n",
    "# compute some summary images (correlation and peak to noisae)\n",
    "cn_filter, pnr = cm.summary_images.correlation_pnr(images, gSig=opts.init['gSig'][0], swap_dim=False) \n",
    "\n",
    "# inspect the summary images and set the parameters\n",
    "inspect_correlation_pnr(cn_filter, pnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot background\n",
    "Crate a figure with background and other images from MC video and save to file"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(ncols=4, figsize=(20, 8))\n",
    "imgs = [mc.total_template_rig, np.median(images, axis=0), cn_filter, pnr]\n",
    "ttls = [\"templates\", \"median bg\", \"cn_filter\", \"pnr\"]\n",
    "for ax, img, ttl in zip(axarr, imgs, ttls):\n",
    "    ax.imshow(img, cmap=\"viridis\")\n",
    "    ax.set(title=ttl)\n",
    "clean_axes(f)\n",
    "save_figure(f, os.path.join(output_fld, MC_TYPE+\"mc_representative_images\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect videos\n",
    "In addition to these plots, it's worth using `compare_videos` in `movie_visualizer.py` to compare raw, rigid mc and pw mc videos:\n",
    "\n",
    "```compare_videos(raw = fnames[0], rigid=fname_new, piecewise=fname_new_els)``` [better to do it outside of this ntotebook as it might block the kernel, you can find the path to the files in the jupyter notebook.]\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"\\n\\nRaw video {fnames[0]}\\n\\nRigid mc: {fname_new}\\n\\nPiecewise mc: {fname_new_els}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute quality metrics"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics for the results (takes ~5 mins)\n",
    "final_size = np.subtract(mc.total_template_els.shape, 2 * bord_px) # remove pixels in the boundaries\n",
    "winsize = 100\n",
    "swap_dim = False\n",
    "resize_fact_flow = .2    # downsample for computing ROF\n",
    "\n",
    "logging.info(\"Computing quality metrics\")\n",
    "\n",
    "\n",
    "# Compute for raw video\n",
    "tmpl_orig, correlations_orig, flows_orig, norms_orig, crispness_orig = cm.motion_correction.compute_metrics_motion_correction(\n",
    "    fnames[0], final_size[0], final_size[1], swap_dim, winsize=winsize, play_flow=False, resize_fact_flow=resize_fact_flow)\n",
    "\n",
    "# Compute for rigid MC\n",
    "tmpl_rig, correlations_rig, flows_rig, norms_rig, crispness_rig = cm.motion_correction.compute_metrics_motion_correction(\n",
    "    mc.fname_tot_rig[0], final_size[0], final_size[1],\n",
    "    swap_dim, winsize=winsize, play_flow=False, resize_fact_flow=resize_fact_flow)\n",
    "\n",
    "# Compute for piecewise MC\n",
    "tmpl_els, correlations_els, flows_els, norms_els, crispness_els = cm.motion_correction.compute_metrics_motion_correction(\n",
    "    mc.fname_tot_els[0], final_size[0], final_size[1],\n",
    "    swap_dim, winsize=winsize, play_flow=False, resize_fact_flow=resize_fact_flow)\n",
    "\n",
    "# Copy metric files to the output directory\n",
    "ttles = [\"raw\", \"rigid\", \"piecewise\"]\n",
    "files = [fnames[0], mc.fname_tot_rig[0], mc.fname_tot_els[0]]\n",
    "metric_files = [os.path.join(fld, get_file_name(f)+\"._metrics.npz\") for f in files]\n",
    "dests = [os.path.join(os.path.split(f)[0], output_fld, os.path.split(f)[1]) for f in metric_files]\n",
    "\n",
    "for src, dest in zip(metric_files, dests):\n",
    "    copyfile(src, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "Look at the correlation between each frame and a reference frame (e.g. avg frame across entire video). If the motion correction worked, the correlation of the motion corrected frames should be higher than that of the raw frame (if stuff moves frames wont't be correlated). This metric is in part influenced by neural activity but not too much. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation with mean frame\n",
    "f = plt.figure(figsize = (20,10))\n",
    "\n",
    "# Plot correlation to mean frame for all frames\n",
    "ax = plt.subplot(211)\n",
    "ax.plot(correlations_orig, color=goldenrod, label=\"original\", lw=3, alpha=1)\n",
    "ax.plot(correlations_rig, color=darkseagreen, label=\"rigid\", lw=2, alpha=.8)\n",
    "ax.plot(correlations_els, color=salmon, label=\"piecewise\", lw=2, alpha=.6)\n",
    "ax.set(title=\"Frame by frame correlation to mean frame\", xlabel=\"frame\", ylabel=\"correlation\")\n",
    "ax.legend()\n",
    "\n",
    "# Plot original vs rigid correlation\n",
    "ax = plt.subplot(234)\n",
    "ax.scatter(correlations_orig, correlations_rig, color=darkseagreen, alpha=.3)\n",
    "ax.plot([0, 1], [0, 1], '--', lw=2, alpha=.8, color=[.4, .4, .4])\n",
    "ax.set(xlabel=\"original\", ylabel=\"rigid\",\n",
    "            xlim=[.3, .7], ylim=[.3, .7])\n",
    "ax.axis('square')\n",
    "\n",
    "# Plot original vs piecewise\n",
    "ax = plt.subplot(235)\n",
    "ax.scatter(correlations_orig, correlations_els, color=salmon, alpha=.3)\n",
    "ax.plot([0, 1], [0, 1], '--', lw=2, alpha=.8, color=[.4, .4, .4])\n",
    "ax.set(xlabel=\"original\", ylabel=\"piecewise\",\n",
    "            xlim=[.3, .7], ylim=[.3, .7])\n",
    "_ = ax.axis('square')\n",
    "\n",
    "\n",
    "# Plot rigid vs piecewise\n",
    "ax = plt.subplot(236)\n",
    "ax.scatter(correlations_rig, correlations_els, color=blackboard, alpha=.3)\n",
    "ax.plot([0, 1], [0, 1], '--', lw=2, alpha=.8, color=[.4, .4, .4])\n",
    "ax.set(xlabel=\"rigid\", ylabel=\"piecewise\",\n",
    "            xlim=[.3, .7], ylim=[.3, .7])\n",
    "_ = ax.axis('square')\n",
    "\n",
    "# save\n",
    "clean_axes(f)\n",
    "save_figure(f, os.path.join(output_fld, \"frames_correlation_to_reference\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crispness\n",
    "Another metric is cripsness. If the motion correction worked. The average frame should be crisper (less blurry). "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print crispness values\n",
    "msg = f\"Crispness:\\n  original: {int(crispness_orig)}\\n  rigid:  {int(crispness_rig)}\\n  piecewise: {int(crispness_els)}\"\n",
    "logging.info(msg)\n",
    "\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optic flow\n",
    "Finally the last metric checks the optic flow across the video. If the video has been correctly motion corrected, the residual optic flow should be minimal. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results of Residual Optical Flow\n",
    "f, axarr = plt.subplots(figsize = (20,10), ncols=2, nrows=3)\n",
    "\n",
    "for i, (fl, ttl) in enumerate(zip(dests, ttles)):\n",
    "    if not os.path.isfile(fl):\n",
    "        raise ValueError\n",
    "    else:\n",
    "        ld = np.load(fl)\n",
    "        \n",
    "    if fl.endswith(\"mmap\"):\n",
    "        mean_img = np.mean(cm.load(fl[:-12] + 'mmap'), 0)[12:-12, 12:-12]\n",
    "    else:\n",
    "        mean_img = np.mean(cm.load(fnames[0]), 0)[12:-12, 12:-12]\n",
    "\n",
    "\n",
    "    lq, hq = np.nanpercentile(mean_img, [.5, 99.5])\n",
    "\n",
    "    axarr[i, 0].imshow(mean_img, vmin=lq, vmax=hq)\n",
    "    axarr[i, 0].set(title=\"Mean image \" + ttl)\n",
    "\n",
    "    flows = ld['flows']\n",
    "    img = axarr[i, 1].imshow(np.mean(np.sqrt(flows[:, :, :, 0]**2 + flows[:, :, :, 1]**2), 0))\n",
    "\n",
    "    divider = make_axes_locatable(axarr[i, 1])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    f.colorbar(img, cax=cax, orientation='vertical')\n",
    "\n",
    "    axarr[i, 1].set(title=\"mean optical flow \" + ttl)\n",
    "\n",
    "# save\n",
    "f.tight_layout()\n",
    "clean_axes(f)\n",
    "save_figure(f, os.path.join(output_fld, \"optic_flow_summary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average residual flow for each condition as an image\n",
    "cmap = \"viridis\"\n",
    "\n",
    "for fl, ttl in zip(dests, ttles):\n",
    "    ld = np.load(fl)\n",
    "    mean_flow = np.mean(np.sqrt(ld['flows'][:, :, :, 0]**2 + ld['flows'][:, :, :, 1]**2), 0)\n",
    "\n",
    "    save_path = os.path.join(output_fld, f\"residual_opticflow_{ttl}\")\n",
    "\n",
    "    plt.imsave(save_path, mean_flow, cmap=cmap)\n",
    "    np.save(save_path+\".npy\", mean_flow)\n",
    "\n",
    "    logging.info(f\"Saving residual optic flow for {ttl} at: {save_path}\")\n",
    ""
   ]
  }
 ]
}